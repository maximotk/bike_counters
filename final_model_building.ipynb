{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import utils\n",
    "from feature_engineering import codify_date, codify_date_2, remove_outliers, get_X_y, covid_19, covid_19_2, add_weather2\n",
    "from feature_engineering import add_weather, add_lag_and_rolling_features\n",
    "from utils import handle_missing_values\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import optuna\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from scipy.stats import uniform, randint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def sin_transformer(period):\n",
    "    return FunctionTransformer(lambda x: np.sin(x / period * 2 * np.pi))\n",
    "\n",
    "\n",
    "def cos_transformer(period):\n",
    "    return FunctionTransformer(lambda x: np.cos(x / period * 2 * np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximochterbeck/Documents/WD/bike_counters/feature_engineering.py:41: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([\"counter_name\", \"date_truncated\"])\n",
      "/Users/maximochterbeck/Documents/WD/bike_counters/feature_engineering.py:72: DtypeWarning: Columns (2,3,44,45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  covid_19_index = pd.read_csv(Path(\"data\") / \"Covid_19_Index.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StringencyIndex_Average</th>\n",
       "      <th>counter_name</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>IsHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46.76</td>\n",
       "      <td>28 boulevard Diderot E-O</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46.76</td>\n",
       "      <td>28 boulevard Diderot E-O</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46.76</td>\n",
       "      <td>28 boulevard Diderot E-O</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46.76</td>\n",
       "      <td>28 boulevard Diderot E-O</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46.76</td>\n",
       "      <td>28 boulevard Diderot E-O</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   StringencyIndex_Average              counter_name  year  month  day  \\\n",
       "0                    46.76  28 boulevard Diderot E-O  2020      9    1   \n",
       "1                    46.76  28 boulevard Diderot E-O  2020      9    1   \n",
       "2                    46.76  28 boulevard Diderot E-O  2020      9    1   \n",
       "3                    46.76  28 boulevard Diderot E-O  2020      9    1   \n",
       "4                    46.76  28 boulevard Diderot E-O  2020      9    1   \n",
       "\n",
       "   day_of_week  hour  is_weekend  IsHoliday  \n",
       "0            1     2       False      False  \n",
       "1            1     3       False      False  \n",
       "2            1     4       False      False  \n",
       "3            1    15       False      False  \n",
       "4            1    18       False      False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_parquet(Path(\"data\") / \"train.parquet\")\n",
    "mdata = codify_date_2(data)\n",
    "mdata = remove_outliers(mdata)\n",
    "mdata = covid_19_2(mdata)\n",
    "#mdata = add_weather2(mdata)\n",
    "#mdata = handle_missing_values(mdata, \"linear\")\n",
    "X, y = get_X_y(mdata)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximochterbeck/Documents/WD/bike_counters/feature_engineering.py:72: DtypeWarning: Columns (2,3,44,45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  covid_19_index = pd.read_csv(Path(\"data\") / \"Covid_19_Index.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>StringencyIndex_Average</th>\n",
       "      <th>counter_id</th>\n",
       "      <th>counter_name</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_name</th>\n",
       "      <th>counter_installation_date</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>counter_technical_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>datetime</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>IsHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>43.77</td>\n",
       "      <td>100007049-102007049</td>\n",
       "      <td>28 boulevard Diderot E-O</td>\n",
       "      <td>100007049</td>\n",
       "      <td>28 boulevard Diderot</td>\n",
       "      <td>2013-01-18</td>\n",
       "      <td>48.846028,2.375429</td>\n",
       "      <td>Y2H15027244</td>\n",
       "      <td>48.846028</td>\n",
       "      <td>2.375429</td>\n",
       "      <td>2021-09-10 01:00:00</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>43.77</td>\n",
       "      <td>100007049-102007049</td>\n",
       "      <td>28 boulevard Diderot E-O</td>\n",
       "      <td>100007049</td>\n",
       "      <td>28 boulevard Diderot</td>\n",
       "      <td>2013-01-18</td>\n",
       "      <td>48.846028,2.375429</td>\n",
       "      <td>Y2H15027244</td>\n",
       "      <td>48.846028</td>\n",
       "      <td>2.375429</td>\n",
       "      <td>2021-09-10 13:00:00</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>43.77</td>\n",
       "      <td>100007049-102007049</td>\n",
       "      <td>28 boulevard Diderot E-O</td>\n",
       "      <td>100007049</td>\n",
       "      <td>28 boulevard Diderot</td>\n",
       "      <td>2013-01-18</td>\n",
       "      <td>48.846028,2.375429</td>\n",
       "      <td>Y2H15027244</td>\n",
       "      <td>48.846028</td>\n",
       "      <td>2.375429</td>\n",
       "      <td>2021-09-10 17:00:00</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>43.77</td>\n",
       "      <td>100007049-102007049</td>\n",
       "      <td>28 boulevard Diderot E-O</td>\n",
       "      <td>100007049</td>\n",
       "      <td>28 boulevard Diderot</td>\n",
       "      <td>2013-01-18</td>\n",
       "      <td>48.846028,2.375429</td>\n",
       "      <td>Y2H15027244</td>\n",
       "      <td>48.846028</td>\n",
       "      <td>2.375429</td>\n",
       "      <td>2021-09-10 19:00:00</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>43.77</td>\n",
       "      <td>100007049-102007049</td>\n",
       "      <td>28 boulevard Diderot E-O</td>\n",
       "      <td>100007049</td>\n",
       "      <td>28 boulevard Diderot</td>\n",
       "      <td>2013-01-18</td>\n",
       "      <td>48.846028,2.375429</td>\n",
       "      <td>Y2H15027244</td>\n",
       "      <td>48.846028</td>\n",
       "      <td>2.375429</td>\n",
       "      <td>2021-09-10 22:00:00</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  StringencyIndex_Average           counter_id  \\\n",
       "0 2021-09-10                    43.77  100007049-102007049   \n",
       "1 2021-09-10                    43.77  100007049-102007049   \n",
       "2 2021-09-10                    43.77  100007049-102007049   \n",
       "3 2021-09-10                    43.77  100007049-102007049   \n",
       "4 2021-09-10                    43.77  100007049-102007049   \n",
       "\n",
       "               counter_name    site_id             site_name  \\\n",
       "0  28 boulevard Diderot E-O  100007049  28 boulevard Diderot   \n",
       "1  28 boulevard Diderot E-O  100007049  28 boulevard Diderot   \n",
       "2  28 boulevard Diderot E-O  100007049  28 boulevard Diderot   \n",
       "3  28 boulevard Diderot E-O  100007049  28 boulevard Diderot   \n",
       "4  28 boulevard Diderot E-O  100007049  28 boulevard Diderot   \n",
       "\n",
       "  counter_installation_date         coordinates counter_technical_id  \\\n",
       "0                2013-01-18  48.846028,2.375429          Y2H15027244   \n",
       "1                2013-01-18  48.846028,2.375429          Y2H15027244   \n",
       "2                2013-01-18  48.846028,2.375429          Y2H15027244   \n",
       "3                2013-01-18  48.846028,2.375429          Y2H15027244   \n",
       "4                2013-01-18  48.846028,2.375429          Y2H15027244   \n",
       "\n",
       "    latitude  longitude            datetime  year  month  day  day_of_week  \\\n",
       "0  48.846028   2.375429 2021-09-10 01:00:00  2021      9   10            4   \n",
       "1  48.846028   2.375429 2021-09-10 13:00:00  2021      9   10            4   \n",
       "2  48.846028   2.375429 2021-09-10 17:00:00  2021      9   10            4   \n",
       "3  48.846028   2.375429 2021-09-10 19:00:00  2021      9   10            4   \n",
       "4  48.846028   2.375429 2021-09-10 22:00:00  2021      9   10            4   \n",
       "\n",
       "   hour  is_weekend  IsHoliday  \n",
       "0     1       False      False  \n",
       "1    13       False      False  \n",
       "2    17       False      False  \n",
       "3    19       False      False  \n",
       "4    22       False      False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.read_parquet(Path(\"data\") / \"final_test.parquet\")\n",
    "X_test = codify_date_2(X_test)\n",
    "X_test = covid_19_2(X_test)\n",
    "#X_test = add_weather2(X_test)\n",
    "#X_test = handle_missing_values(X_test, \"linear\")\n",
    "\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index1</th>\n",
       "      <th>index2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51435</th>\n",
       "      <td>51435</td>\n",
       "      <td>51435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51436</th>\n",
       "      <td>51436</td>\n",
       "      <td>51436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51437</th>\n",
       "      <td>51437</td>\n",
       "      <td>51437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51438</th>\n",
       "      <td>51438</td>\n",
       "      <td>51438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51439</th>\n",
       "      <td>51439</td>\n",
       "      <td>51439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51440 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index1  index2\n",
       "0           0       0\n",
       "1           1       1\n",
       "2           2       2\n",
       "3           3       3\n",
       "4           4       4\n",
       "...       ...     ...\n",
       "51435   51435   51435\n",
       "51436   51436   51436\n",
       "51437   51437   51437\n",
       "51438   51438   51438\n",
       "51439   51439   51439\n",
       "\n",
       "[51440 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save original index\n",
    "X_original = pd.read_parquet(Path(\"data\") / \"final_test.parquet\")\n",
    "X_original.loc[:, \"index1\"] = X_original.index\n",
    "X_original = codify_date_2(X_original)\n",
    "\n",
    "# Merge DataFrames\n",
    "X_test.loc[:, \"index2\"] = X_test.index\n",
    "merged_df = X_test.merge(X_original, on=[\"datetime\", \"counter_name\"], how=\"left\")\n",
    "\n",
    "merged_df = merged_df.sort_values(\"index1\")\n",
    "display(merged_df[[\"index1\", \"index2\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.drop(columns=[\"counter_id\", \"site_id\", \"site_name\", \n",
    "                                \"counter_installation_date\", \n",
    "                              \"coordinates\", \"counter_technical_id\",\n",
    "                              \"latitude\", \"longitude\", \"datetime\", \"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_cols = [\\'StringencyIndex_Average\\', \\'counter_name\\', \\'year\\', \\'month\\', \\'day\\',\\n       \\'day_of_week\\', \\'hour\\', \\'is_weekend\\', \\'IsHoliday\\', \"t\"]\\n\\nX = X[X_cols]\\nX_test = X_test[X_cols]\\n\\ndisplay(X)\\ndisplay(X_test)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"X_cols = ['StringencyIndex_Average', 'counter_name', 'year', 'month', 'day',\n",
    "       'day_of_week', 'hour', 'is_weekend', 'IsHoliday', \"t\"]\n",
    "\n",
    "X = X[X_cols]\n",
    "X_test = X_test[X_cols]\n",
    "\n",
    "display(X)\n",
    "display(X_test)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#numerical_columns = [\\'t\\', \\'rr1\\', \\'u\\', \\'ht_neige\\', \\'raf10\\', \\'ff\\', \\'ww\\', \\'etat_sol\\', \\'tend\\']\\ncategorical_columns = [\"counter_name\", \"year\", \"month\", \"day\", \"day_of_week\", \"is_weekend\", \"IsHoliday\"]\\n\\npreprocessor = ColumnTransformer(transformers=[\\n    (\"cat\", OneHotEncoder(handle_unknown=\\'ignore\\', sparse_output=False), categorical_columns),\\n    (\"hour_sin\", sin_transformer(24), [\"hour\"]),\\n    (\"hour_cos\", cos_transformer(24), [\"hour\"]),\\n], remainder=\\'passthrough\\')\\n\\npipeline = Pipeline([\\n    (\"preprocessor\", preprocessor),\\n    (\"regressor\", XGBRegressor())\\n])\\n\\n# Fit the pipeline to the training data\\npipeline.fit(X, y)\\n\\ny_pred = pipeline.predict(X_test)\\ny_pred = y_pred[merged_df[\"index2\"]]\\n\\nresults = pd.DataFrame(\\n    dict(\\n        Id=np.arange(y_pred.shape[0]),\\n        log_bike_count=y_pred,\\n    )\\n)\\nresults.to_csv(\"submission_maxim.csv\", index=False)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#numerical_columns = ['t', 'rr1', 'u', 'ht_neige', 'raf10', 'ff', 'ww', 'etat_sol', 'tend']\n",
    "categorical_columns = [\"counter_name\", \"year\", \"month\", \"day\", \"day_of_week\", \"is_weekend\", \"IsHoliday\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"cat\", OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_columns),\n",
    "    (\"hour_sin\", sin_transformer(24), [\"hour\"]),\n",
    "    (\"hour_cos\", cos_transformer(24), [\"hour\"]),\n",
    "], remainder='passthrough')\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", XGBRegressor())\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_pred = y_pred[merged_df[\"index2\"]]\n",
    "\n",
    "results = pd.DataFrame(\n",
    "    dict(\n",
    "        Id=np.arange(y_pred.shape[0]),\n",
    "        log_bike_count=y_pred,\n",
    "    )\n",
    ")\n",
    "results.to_csv(\"submission_maxim.csv\", index=False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Define the numerical and categorical columns\\n#numerical_columns = [\\'t\\', \\'rr1\\', \\'u\\', \\'ht_neige\\', \\'raf10\\', \\'ff\\', \\'ww\\', \\'etat_sol\\', \\'tend\\']\\ncategorical_columns = [\"counter_name\", \"year\", \"month\", \"day\", \"day_of_week\", \"is_weekend\", \"IsHoliday\"]\\n\\n# Create the preprocessor\\npreprocessor = ColumnTransformer(transformers=[\\n    (\"cat\", OneHotEncoder(handle_unknown=\\'ignore\\', sparse_output=False), categorical_columns),\\n    (\"hour_sin\", sin_transformer(24), [\"hour\"]),\\n    (\"hour_cos\", cos_transformer(24), [\"hour\"]),\\n], remainder=\\'passthrough\\')\\n\\n# Define the objective function for Optuna optimization\\ndef objective(trial):\\n    # Define the hyperparameter search space\\n    params = {\\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\\n        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\\n        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\\n        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\\n        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\\n        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 10.0),\\n        \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 1e-5, 10.0),\\n        \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-5, 10.0),\\n    }\\n\\n    # Define the pipeline with the trial\\'s hyperparameters\\n    pipeline = Pipeline([\\n        (\"preprocessor\", preprocessor),\\n        (\"regressor\", XGBRegressor(**params, random_state=42))\\n    ])\\n\\n    # Perform cross-validation and return the negative mean squared error\\n    scores = cross_val_score(pipeline, X, y, cv=5, scoring=make_scorer(mean_squared_error, greater_is_better=False))\\n    return np.mean(scores)\\n\\n# Create an Optuna study and optimize the objective\\nstudy = optuna.create_study(direction=\"minimize\")\\nstudy.optimize(objective, n_trials=50)\\n\\n# Print the best hyperparameters\\nprint(\"Best hyperparameters:\", study.best_params)\\n\\n# Train the final model with the best hyperparameters\\nbest_params = study.best_params\\nfinal_pipeline = Pipeline([\\n    (\"preprocessor\", preprocessor),\\n    (\"regressor\", XGBRegressor(**best_params, random_state=42))\\n])\\nfinal_pipeline.fit(X, y)\\n\\n# Make predictions on the test set\\ny_pred = final_pipeline.predict(X_test)\\ny_pred = y_pred[merged_df[\"index2\"]]\\n\\n# Save the predictions to a CSV file\\nresults = pd.DataFrame(\\n    dict(\\n        Id=np.arange(y_pred.shape[0]),\\n        log_bike_count=y_pred,\\n    )\\n)\\nresults.to_csv(\"submission_maxim_tuned_optuna.csv\", index=False)\\n\\nprint(\"Tuned model predictions saved to submission_maxim_tuned_optuna.csv\")'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Define the numerical and categorical columns\n",
    "#numerical_columns = ['t', 'rr1', 'u', 'ht_neige', 'raf10', 'ff', 'ww', 'etat_sol', 'tend']\n",
    "categorical_columns = [\"counter_name\", \"year\", \"month\", \"day\", \"day_of_week\", \"is_weekend\", \"IsHoliday\"]\n",
    "\n",
    "# Create the preprocessor\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"cat\", OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_columns),\n",
    "    (\"hour_sin\", sin_transformer(24), [\"hour\"]),\n",
    "    (\"hour_cos\", cos_transformer(24), [\"hour\"]),\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Define the objective function for Optuna optimization\n",
    "def objective(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 10.0),\n",
    "        \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 1e-5, 10.0),\n",
    "        \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-5, 10.0),\n",
    "    }\n",
    "\n",
    "    # Define the pipeline with the trial's hyperparameters\n",
    "    pipeline = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"regressor\", XGBRegressor(**params, random_state=42))\n",
    "    ])\n",
    "\n",
    "    # Perform cross-validation and return the negative mean squared error\n",
    "    scores = cross_val_score(pipeline, X, y, cv=5, scoring=make_scorer(mean_squared_error, greater_is_better=False))\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Create an Optuna study and optimize the objective\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "best_params = study.best_params\n",
    "final_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", XGBRegressor(**best_params, random_state=42))\n",
    "])\n",
    "final_pipeline.fit(X, y)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = final_pipeline.predict(X_test)\n",
    "y_pred = y_pred[merged_df[\"index2\"]]\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "results = pd.DataFrame(\n",
    "    dict(\n",
    "        Id=np.arange(y_pred.shape[0]),\n",
    "        log_bike_count=y_pred,\n",
    "    )\n",
    ")\n",
    "results.to_csv(\"submission_maxim_tuned_optuna.csv\", index=False)\n",
    "\n",
    "print(\"Tuned model predictions saved to submission_maxim_tuned_optuna.csv\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Define the numerical and categorical columns\\n#numerical_columns = [\\'u\\']\\ncategorical_columns = [\"counter_name\", \"year\", \"month\", \"day\", \"day_of_week\", \"is_weekend\", \"IsHoliday\"]\\n\\n# Create the preprocessor\\npreprocessor = ColumnTransformer(transformers=[\\n    (\"cat\", OneHotEncoder(handle_unknown=\\'ignore\\', sparse_output=False), categorical_columns),\\n    (\"hour_sin\", sin_transformer(24), [\"hour\"]),\\n    (\"hour_cos\", cos_transformer(24), [\"hour\"]),\\n], remainder=\\'passthrough\\')\\n\\n# Define the pipeline\\npipeline = Pipeline([\\n    (\"preprocessor\", preprocessor),\\n    (\"regressor\", XGBRegressor(random_state=42))\\n])\\n\\n# Define the parameter grid for RandomizedSearchCV\\nparam_distributions = {\\n    \"regressor__n_estimators\": randint(100, 500),\\n    \"regressor__max_depth\": randint(3, 10),\\n    \"regressor__learning_rate\": uniform(0.01, 0.2),\\n    \"regressor__subsample\": uniform(0.6, 0.4),\\n    \"regressor__colsample_bytree\": uniform(0.6, 0.4),\\n    \"regressor__gamma\": uniform(0, 5),\\n    \"regressor__reg_alpha\": uniform(1e-5, 10),\\n    \"regressor__reg_lambda\": uniform(1e-5, 10),\\n}\\n\\n# Define RandomizedSearchCV\\nrandom_search = RandomizedSearchCV(\\n    estimator=pipeline,\\n    param_distributions=param_distributions,\\n    n_iter=50,  # Number of parameter settings to try\\n    scoring=\"neg_mean_squared_error\",\\n    cv=5,\\n    verbose=1,\\n    random_state=42,\\n    n_jobs=-1  # Use all available cores\\n)\\n\\n# Fit RandomizedSearchCV\\nrandom_search.fit(X, y)\\n\\n# Get the best pipeline with tuned hyperparameters\\nbest_pipeline = random_search.best_estimator_\\n\\n# Print the best parameters\\nprint(\"Best parameters found:\", random_search.best_params_)\\n\\n# Fit the final pipeline on the entire training set\\nbest_pipeline.fit(X, y)\\n\\n# Make predictions on the test set\\ny_pred = best_pipeline.predict(X_test)\\ny_pred = y_pred[merged_df[\"index2\"]]\\n\\n# Save the predictions to a CSV file\\nresults = pd.DataFrame(\\n    dict(\\n        Id=np.arange(y_pred.shape[0]),\\n        log_bike_count=y_pred,\\n    )\\n)\\nresults.to_csv(\"submission_maxim_tuned_randomsearch.csv\", index=False)\\n\\nprint(\"Tuned model predictions saved to submission_maxim_tuned_randomsearch.csv\")'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the numerical and categorical columns\n",
    "#numerical_columns = ['u']\n",
    "categorical_columns = [\"counter_name\", \"year\", \"month\", \"day\", \"day_of_week\", \"is_weekend\", \"IsHoliday\"]\n",
    "\n",
    "# Create the preprocessor\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"cat\", OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_columns),\n",
    "    (\"hour_sin\", sin_transformer(24), [\"hour\"]),\n",
    "    (\"hour_cos\", cos_transformer(24), [\"hour\"]),\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", XGBRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Define the parameter grid for RandomizedSearchCV\n",
    "param_distributions = {\n",
    "    \"regressor__n_estimators\": randint(100, 500),\n",
    "    \"regressor__max_depth\": randint(3, 10),\n",
    "    \"regressor__learning_rate\": uniform(0.01, 0.2),\n",
    "    \"regressor__subsample\": uniform(0.6, 0.4),\n",
    "    \"regressor__colsample_bytree\": uniform(0.6, 0.4),\n",
    "    \"regressor__gamma\": uniform(0, 5),\n",
    "    \"regressor__reg_alpha\": uniform(1e-5, 10),\n",
    "    \"regressor__reg_lambda\": uniform(1e-5, 10),\n",
    "}\n",
    "\n",
    "# Define RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,  # Number of parameter settings to try\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    random_state=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X, y)\n",
    "\n",
    "# Get the best pipeline with tuned hyperparameters\n",
    "best_pipeline = random_search.best_estimator_\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found:\", random_search.best_params_)\n",
    "\n",
    "# Fit the final pipeline on the entire training set\n",
    "best_pipeline.fit(X, y)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "y_pred = y_pred[merged_df[\"index2\"]]\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "results = pd.DataFrame(\n",
    "    dict(\n",
    "        Id=np.arange(y_pred.shape[0]),\n",
    "        log_bike_count=y_pred,\n",
    "    )\n",
    ")\n",
    "results.to_csv(\"submission_maxim_tuned_randomsearch.csv\", index=False)\n",
    "\n",
    "print(\"Tuned model predictions saved to submission_maxim_tuned_randomsearch.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
